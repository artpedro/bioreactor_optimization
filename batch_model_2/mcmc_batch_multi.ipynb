{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import scipy\n",
    "import glob\n",
    "import os\n",
    "from sklearn.metrics import root_mean_squared_error,r2_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dados\\25.45nh60ab20.csv\n",
      "../dados\\25.46nh30ab30.csv\n",
      "../dados\\25.47nh5ab80.csv\n",
      "../dados\\5.100nh40ab80.csv\n",
      "../dados\\5.102nh20ab40.csv\n",
      "../dados\\5.103nh40ab30.csv\n",
      "../dados\\5.106nh100ab40.csv\n",
      "../dados\\5.107nh55ab55.csv\n",
      "../dados\\5.109nh5ab55.csv\n",
      "../dados\\5.110nh10ab55.csv\n",
      "../dados\\5.112nh78ab35.csv\n",
      "../dados\\5.48nh20ab80.csv\n",
      "../dados\\5.80nh12ab40.csv\n",
      "../dados\\5.81nh5ab30.csv\n",
      "../dados\\nh60ab80.csv\n",
      "Index(['ester_mm', 'amox_mm', 'apa_mm', 'aoh_mm', 'apa_t'], dtype='object')\n",
      "['25.45nh60ab20', '25.46nh30ab30', '25.47nh5ab80', '5.100nh40ab80', '5.102nh20ab40', '5.103nh40ab30', '5.106nh100ab40', '5.107nh55ab55', '5.109nh5ab55', '5.110nh10ab55', '5.112nh78ab35', '5.48nh20ab80', '5.80nh12ab40', '5.81nh5ab30', 'nh60ab80']\n",
      "[array([20.,  0., 60.,  0.]), array([30.,  0., 30.,  0.]), array([80.,  0.,  5.,  0.]), array([80.,  0., 40.,  0.]), array([40.5       ,  0.        , 21.75      ,  3.37262013]), array([30.4 ,  0.  , 43.  ,  2.55]), array([4.00389864e+01, 6.40149834e-02, 1.00045181e+02, 1.42108547e+00]), array([55.      ,  0.      , 55.      ,  0.623377]), array([55.,  0.,  5.,  0.]), array([55.,  0., 10.,  0.]), array([32.5,  0. , 78. ,  2.5]), array([80.,  0., 20.,  0.]), array([38.75,  0.  , 12.  ,  1.4 ]), array([30.,  0.,  5.,  0.]), array([80.,  0., 60.,  0.])]\n"
     ]
    }
   ],
   "source": [
    "CIs = []\n",
    "\n",
    "def import_dfs():\n",
    "    # Path to the folder containing CSV files\n",
    "    folder_path = '../dados/'\n",
    "\n",
    "    # Get a list of all CSV files in the folder\n",
    "    csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "    # Initialize an empty list to hold dataframes\n",
    "    data_frames = []\n",
    "\n",
    "    # Read the first CSV file to establish the schema\n",
    "    schema = ['ester_mm', 'amox_mm', 'apa_mm', 'aoh_mm','apa_t']\n",
    "\n",
    "\n",
    "    # Load each remaining CSV file, reorder columns, and append to the list\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)  \n",
    "        print(file)\n",
    "        df = df[schema]  # Reorder columns to match the schema\n",
    "        data_frames.append(df)\n",
    "        CIs.append(df.iloc[0,:4].to_numpy())\n",
    "    csv_files = [name.split('\\\\')[-1].rstrip('.csv') for name in csv_files]\n",
    "    return data_frames,csv_files \n",
    "data_frames,file_list = import_dfs()\n",
    "print(data_frames[0].columns)\n",
    "print(file_list)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cez = 1\n",
    "\n",
    "k2 = 0.1 \n",
    "k3 = 2\n",
    "k4 = 0.3\n",
    "k5 = 0.4\n",
    "KS = 5.0\n",
    "KP = 0.9\n",
    "KN = 4.0\n",
    "kmenos4 = 0.01\n",
    "P = np.zeros(8)\n",
    "P[0]   = k2 \n",
    "P[1]   = k3    \n",
    "P[2]   = k4      \n",
    "P[3]   = k5      \n",
    "P[4]   = KS     \n",
    "P[5]   = KP      \n",
    "P[6]   = KN      \n",
    "P[7]   = kmenos4\n",
    "\n",
    "Np = len(P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enzymic_amox(t,y, \n",
    "k2,\n",
    "k3,\n",
    "k4,\n",
    "k5,\n",
    "KS,\n",
    "KP,\n",
    "KN,\n",
    "kmenos4,\n",
    "):\n",
    "    Cez = 1\n",
    "    CAB = y[0]\n",
    "    CAN = y[1]\n",
    "    CNH = y[2]\n",
    "    CAOH = y[3]\n",
    "\n",
    "    RP = (Cez)/(k3 * KN + k4 * CNH + k5 * CNH) * ((k2 * k4 * CAB * CNH)/ (KS) - (kmenos4 * CAN * (k3 * KN + k5 * CNH)/KP))\n",
    "    RB = Cez * (k3 * KN + k5 * CNH) / (k3 * KN + k4 * CNH + k5 * CNH) * ((k2 * CAB) / KS - (kmenos4 * CAN) / KP)\n",
    "    RS = -(RP + RB)\n",
    "    RNu = -(RP)\n",
    "\n",
    "    dy = np.zeros(4)\n",
    "\n",
    "    dy[0] =  RS       \n",
    "    dy[1] =  RP\n",
    "    dy[2] =  -(RP)  \n",
    "    dy[3] = RB      \n",
    "    \n",
    "    return np.array(dy)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ode15s_amox(P, CI, t):\n",
    "    return scipy.integrate.solve_ivp(enzymic_amox,t_span=(t[0],t[-1]),t_eval=t,y0=CI,method='BDF',args=P).y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate\n",
    "\n",
    "\n",
    "def ode15s_amox(P, CI, t):\n",
    "    try:\n",
    "        sol = scipy.integrate.solve_ivp(\n",
    "            enzymic_amox, \n",
    "            t_span=(t[0], t[-1]), \n",
    "            t_eval=t, \n",
    "            y0=CI, \n",
    "            method='RK45', \n",
    "            args=P, \n",
    "            #atol=1e-8, \n",
    "            #tol=1e-6\n",
    "        )\n",
    "        if sol.status != 0:\n",
    "            raise ValueError(\"ODE solver failed to converge\")\n",
    "        return sol.y.T\n",
    "    except Exception as e:\n",
    "        print(f\"Solver failed with error: {e}\")\n",
    "        # Handle solver failure (e.g., return NaNs or retry with different parameters)\n",
    "        return np.full((len(CI), len(t)), np.nan).T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmc(P,priori,N=5000,ode_solver=ode15s_amox,status=False):\n",
    "\n",
    "    Np = len(P)\n",
    "    # Extraindo dados\n",
    "    exps = []\n",
    "    times = []\n",
    "    \n",
    "    for i in range(len(CIs)):\n",
    "        t = data_frames[i].loc[:,'apa_t'].dropna().to_numpy()\n",
    "\n",
    "        exp = np.zeros((len(t),4))\n",
    "        \n",
    "        exp[:,0]  = data_frames[i].loc[:,'ester_mm'].dropna().to_numpy()\n",
    "        exp[:,1]  = data_frames[i].loc[:,'amox_mm'].dropna().to_numpy()\n",
    "        exp[:,2] = data_frames[i].loc[:,'apa_mm'].dropna().to_numpy()\n",
    "        exp[:,3]  = data_frames[i].loc[:,'aoh_mm'].dropna().to_numpy()\n",
    "        exps.append(exp)\n",
    "\n",
    "        times.append(t)\n",
    "    Cez = 1\n",
    "    refs = []\n",
    "    desvio = np.zeros((4,len(CIs)))\n",
    "\n",
    "    for i in range(len(CIs)):\n",
    "        t = times[i]\n",
    "        ref = np.zeros((len(t),4))\n",
    "        Y = ode_solver(P,CIs[i],t)\n",
    "\n",
    "        ref[:,0]   =  Y[:,0]      \n",
    "        ref[:,1]   =  Y[:,1]    \n",
    "        ref[:,2]   =  Y[:,2]      \n",
    "        ref[:,3]  =   Y[:,3]\n",
    "\n",
    "        refs.append(ref)\n",
    "\n",
    "        desvio[0,i] =  0.1*max(ref[:,0]) \n",
    "        desvio[1,i] =  0.1*max(ref[:,1])\n",
    "        desvio[2,i] =  0.1*max(ref[:,2])\n",
    "        desvio[3,i] =  0.1*max(ref[:,3])\n",
    "    \n",
    "    waux      = 6e-3 \n",
    "    media_g   = 1       #Média gaussiana\n",
    "    desviop_g = 0.6     #Desvio dos parâmetros ao utilizar priori gaussian\n",
    "\n",
    "    estimate = [i for i in range(10)]\n",
    "    Nfix = len(estimate)\n",
    "\n",
    "    p_ref = P                   \n",
    "    p_old = P                     \n",
    "\n",
    "    media_MCMC = media_g*P\n",
    "    desvio_P   = desviop_g*P\n",
    "\n",
    "    w = np.ones((1,Np))   \n",
    "    w = w*waux  \n",
    "\n",
    "    parametro_exato = (p_ref*np.ones((N,1))).T\n",
    "    \n",
    "    aceitacao    = np.zeros((1,N))  \n",
    "    cadeia       = np.zeros((Np,N)) \n",
    "    conv_likeli  = np.zeros((1,N))\n",
    "    k=0\n",
    "    lk_old = 0\n",
    "        \n",
    "    for i in range(len(CIs)):\n",
    "        Lk_1 = np.dot((exps[i][:,0] - refs[i][:,0]),(exps[i][:,0] - refs[i][:,0]).T) / (desvio[0,i]**2)     \n",
    "        Lk_2 = np.dot((exps[i][:,1] - refs[i][:,1]),(exps[i][:,1] - refs[i][:,1]).T) / (desvio[1,i]**2)      \n",
    "        Lk_3 = np.dot((exps[i][:,2] - refs[i][:,2]),(exps[i][:,2] - refs[i][:,2]).T) / (desvio[2,i]**2)       \n",
    "        Lk_4 = np.dot((exps[i][:,3] - refs[i][:,3]),(exps[i][:,3] - refs[i][:,3]).T) / (desvio[3,i]**2)  \n",
    "        lk_partial = Lk_1 + Lk_2 + Lk_3 + Lk_4\n",
    "        lk_old += lk_partial\n",
    "    \n",
    "\n",
    "    prior_old = np.sum((((p_old - media_MCMC))/((desvio_P)**2)))\n",
    "    cadeia[:,0] = p_old\n",
    "    \n",
    "    # Contador para verificar a aceitação\n",
    "    for i in range(0, N):  # Python index starts at 0, MATLAB at 1\n",
    "        progress = (i / N) * 100\n",
    "        if status:\n",
    "            print(progress,end='\\r')\n",
    "        # New parameter vector\n",
    "        P_new = p_old + w * np.random.randn(Np) * p_old\n",
    "        #print('p_new: ', P_new)\n",
    "        # Simulate using ODE solver\n",
    "\n",
    "        chain_ref = []\n",
    "        for j in range(len(CIs)):\n",
    "            t = times[j]\n",
    "            ref = np.zeros((len(t),4))\n",
    "\n",
    "            Y = ode_solver(P_new[0],CIs[j],t)\n",
    "            ref[:,0]  =  Y[:,0]      \n",
    "            ref[:,1]  =  Y[:,1]    \n",
    "            ref[:,2]  =  Y[:,2]      \n",
    "            ref[:,3] =   Y[:,3]\n",
    "            chain_ref.append(ref)\n",
    "\n",
    "\n",
    "        # Calculate new prior\n",
    "        Prior_new = np.sum(((P_new[0] - media_MCMC) / desvio_P) ** 2)\n",
    "\n",
    "        Lk_new = 0\n",
    "        # Likelihood calculations\n",
    "        for j in range(len(CIs)):\n",
    "            Lk_1 = np.dot((exps[j][:,0] - chain_ref[j][:,0]),(exps[j][:,0] - chain_ref[j][:,0]).T) / (desvio[0,j]**2)     \n",
    "            Lk_2 = np.dot((exps[j][:,1] - chain_ref[j][:,1]),(exps[j][:,1] - chain_ref[j][:,1]).T) / (desvio[1,j]**2)      \n",
    "            Lk_3 = np.dot((exps[j][:,2] - chain_ref[j][:,2]),(exps[j][:,2] - chain_ref[j][:,2]).T) / (desvio[2,j]**2)       \n",
    "            Lk_4 = np.dot((exps[j][:,3] - chain_ref[j][:,3]),(exps[j][:,3] - chain_ref[j][:,3]).T) / (desvio[3,j]**2)  \n",
    "            lk_partial = Lk_1 + Lk_2 + Lk_3 + Lk_4\n",
    "            Lk_new += lk_partial \n",
    "    \n",
    "        # MCMC acceptance check\n",
    "        if np.log(random.random()) < (-0.5 * (Lk_new + Prior_new - lk_old - prior_old)):\n",
    "            p_old = P_new\n",
    "            lk_old = Lk_new\n",
    "            prior_old = Prior_new\n",
    "            k += 1\n",
    "        \n",
    "        # Store results\n",
    "        aceitacao[0,i] = k\n",
    "        cadeia[:, i] = p_old\n",
    "        conv_likeli[0,i] = lk_old + prior_old\n",
    "    print(\"aceitacao: \", k/N, 'k: ', k)\n",
    "    fig,ax = plt.subplots(2,4,figsize=[20,8])\n",
    "    ax = ax.flatten()\n",
    "    labels = ['k2',\n",
    "'k3',\n",
    "'k4',\n",
    "'k5',\n",
    "'KS',\n",
    "'KP',\n",
    "'KN',\n",
    "'kmenos4']\n",
    "    for idx,g in enumerate(ax):\n",
    "        g.plot(cadeia[idx,:])    \n",
    "        g.set_title(labels[idx])\n",
    "        g.set_ylabel(\"Value\")\n",
    "        g.set_xlabel(\"Iteration\")\n",
    "    fig.savefig(f\"./chains/multi_{priori}_{N}.png\",dpi=400)\n",
    "    plt.close()    \n",
    "\n",
    "    aq = int(0.9 * N)  # Starting index for the burn-in period\n",
    "    IC = 0.99          # Confidence interval level\n",
    "\n",
    "    # Confidence interval bounds\n",
    "    xaux = (1 - IC) / 2\n",
    "    IC_inf = xaux\n",
    "    IC_sup = 1 - xaux\n",
    "    estimate = [i for i in range(Np)]\n",
    "\n",
    "    amostra = N - aq + 1\n",
    "    amostras = [] # [CIs, Nics, t, subs]\n",
    "\n",
    "\n",
    "    output_par = np.zeros((amostra,Np))\n",
    "    for i in range(len(CIs)):\n",
    "        t = times[i]\n",
    "        inst_amostra = np.zeros((len(list(range(aq, N + 1))),len(t),4))\n",
    "\n",
    "        for idx,j in enumerate(range(aq, N + 1)):\n",
    "            ii = j - aq\n",
    "            paux = cadeia[:, j - 1]\n",
    "            output_par[ii,:] = paux\n",
    "            \n",
    "            Y = ode_solver(paux,CIs[i],t)\n",
    "            inst_amostra[idx,:,0]  = Y[:,0]\n",
    "            inst_amostra[idx,:,1] = Y[:,1]\n",
    "            inst_amostra[idx,:,2] = Y[:,2]\n",
    "            inst_amostra[idx,:,3] = Y[:,3]\n",
    "        \n",
    "        amostras.append(inst_amostra)\n",
    "\n",
    "\n",
    "    AB_media = []\n",
    "    AN_media = []\n",
    "    NH_media = []\n",
    "    AOH_media =[]\n",
    "    AB_sup = []\n",
    "    AN_sup = []\n",
    "    NH_sup = []\n",
    "    AOH_sup =[]\n",
    "    AB_inf = []\n",
    "    AN_inf = []\n",
    "    NH_inf = []\n",
    "    AOH_inf =  []   \n",
    "\n",
    "    for i in range(len(CIs)):\n",
    "        t = times[i]\n",
    "        amostra = amostras[i]\n",
    "        \n",
    "        AB_mean = np.zeros(len(t))\n",
    "        AB_inferior = np.zeros(len(t))\n",
    "        AB_superior = np.zeros(len(t))\n",
    "        NH_mean = np.zeros(len(t))\n",
    "        NH_inferior = np.zeros(len(t))\n",
    "        NH_superior = np.zeros(len(t))\n",
    "\n",
    "        for j in range(len(t)):    \n",
    "            AB_mean[j] = np.mean(amostra[:,j,0])\n",
    "            y = np.percentile(amostra[:, j,0], [IC_inf * 100, IC_sup * 100])\n",
    "            AB_inferior[j] = y[0]\n",
    "            AB_superior[j] = y[1]\n",
    "\n",
    "            NH_mean[j] = np.mean(amostra[:, j,2])\n",
    "            y = np.percentile(amostra[:, j,2], [IC_inf * 100, IC_sup * 100])\n",
    "            NH_inferior[j] = y[0]\n",
    "            NH_superior[j] = y[1]\n",
    "        \n",
    "        AN_mean = np.zeros(len(t))\n",
    "        AN_inferior = np.zeros(len(t))\n",
    "        AN_superior = np.zeros(len(t))\n",
    "        AOH_mean = np.zeros(len(t))\n",
    "        AOH_inferior = np.zeros(len(t))\n",
    "        AOH_superior = np.zeros(len(t))\n",
    "        \n",
    "        for j in range(len(t)):\n",
    "            AN_mean[j] = np.mean(amostra[:, j, 1])\n",
    "            y = np.percentile(amostra[:, j,1], [IC_inf * 100, IC_sup * 100])\n",
    "            AN_inferior[j] = y[0]\n",
    "            AN_superior[j] = y[1]\n",
    "\n",
    "            AOH_mean[j] = np.mean(amostra[:, j,3])\n",
    "            y = np.percentile(amostra[:, j,3], [IC_inf * 100, IC_sup * 100])\n",
    "            AOH_inferior[j] = y[0]\n",
    "            AOH_superior[j] = y[1]\n",
    "\n",
    "        AB_media.append(AB_mean)\n",
    "        NH_media.append(NH_mean)\n",
    "        AB_inf.append(AB_inferior)\n",
    "        AB_sup.append(AB_superior)\n",
    "        NH_inf.append(NH_inferior)\n",
    "        NH_sup.append(NH_superior)\n",
    "        AN_media.append(AN_mean)\n",
    "        AOH_media.append(AOH_mean)\n",
    "        AN_inf.append(AN_inferior)\n",
    "        AN_sup.append(AN_superior)\n",
    "        AOH_inf.append(AOH_inferior)\n",
    "        AOH_sup.append(AOH_superior)\n",
    "\n",
    "    # individual plot\n",
    "    # Ensure 'results' directory exists\n",
    "    results_dir = 'results_mcmc/'\n",
    "\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    for i in range(len(CIs)):\n",
    "        names = ['POH-PGME','Amoxicillin','6-APA','POHPG']\n",
    "        t = times[i]\n",
    "        style = ['or','og','ob','ok']\n",
    "        mstyle = ['-r','-g','-b','-k']\n",
    "        medidas = [\n",
    "            [AB_media[i], AB_inf[i], AB_sup[i]],\n",
    "            [AN_media[i], AN_inf[i], AN_sup[i]],\n",
    "            [NH_media[i], NH_inf[i], NH_sup[i]],\n",
    "            [AOH_media[i],AOH_inf[i],AOH_sup[i]]\n",
    "        ]\n",
    "        fig,ax = plt.subplots(2,2,figsize=(10,10))\n",
    "        for idx,axis in enumerate(ax.flatten()):\n",
    "            sname = names[idx]\n",
    "            medida = medidas[idx]\n",
    "            \n",
    "            axis.plot(t, exps[i][:,idx], style[idx], label=sname)\n",
    "            axis.plot(t, medida[0], mstyle[idx])\n",
    "            axis.plot(t, medida[1], '--r',linewidth=0.5)\n",
    "            axis.plot(t, medida[2], '--r',linewidth=0.5) \n",
    "            axis.set_xlabel('Tempo (min)')\n",
    "            axis.set_ylabel(f'Concentração de {sname} (mm)')  # Use f-string for proper string formatting\n",
    "            axis.legend()  # Adjust legend position\n",
    "        fig.savefig(os.path.join(results_dir, f\"{i}_multi_{priori}_{N}_{file_list[i]}_mcmc.png\"), dpi=300)\n",
    "        plt.close()  # Close the figure to release memory\n",
    "    return output_par,k/N\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1k = mcmc(P=P,priori='donald',N=100000,status=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aceitacao:  0.49 k:  49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.09035903, 2.12223599, 0.29474951, 0.40643681, 5.9204636 ,\n",
       "         0.88916506, 3.7795099 , 0.01056602],\n",
       "        [0.09080204, 2.10631557, 0.29427064, 0.40627059, 5.96667019,\n",
       "         0.89052923, 3.79005801, 0.01061014],\n",
       "        [0.09080204, 2.10631557, 0.29427064, 0.40627059, 5.96667019,\n",
       "         0.89052923, 3.79005801, 0.01061014],\n",
       "        [0.09065665, 2.09077858, 0.2939206 , 0.40610185, 5.97746716,\n",
       "         0.88109922, 3.76076942, 0.0106506 ],\n",
       "        [0.09065665, 2.09077858, 0.2939206 , 0.40610185, 5.97746716,\n",
       "         0.88109922, 3.76076942, 0.0106506 ],\n",
       "        [0.09036558, 2.08503362, 0.29499208, 0.40020741, 5.98538513,\n",
       "         0.88494094, 3.76345214, 0.01056966],\n",
       "        [0.09036558, 2.08503362, 0.29499208, 0.40020741, 5.98538513,\n",
       "         0.88494094, 3.76345214, 0.01056966],\n",
       "        [0.09036558, 2.08503362, 0.29499208, 0.40020741, 5.98538513,\n",
       "         0.88494094, 3.76345214, 0.01056966],\n",
       "        [0.09044416, 2.09736676, 0.29269942, 0.39878208, 6.02081278,\n",
       "         0.88851318, 3.75433982, 0.01062183],\n",
       "        [0.09044416, 2.09736676, 0.29269942, 0.39878208, 6.02081278,\n",
       "         0.88851318, 3.75433982, 0.01062183],\n",
       "        [0.09044416, 2.09736676, 0.29269942, 0.39878208, 6.02081278,\n",
       "         0.88851318, 3.75433982, 0.01062183]]),\n",
       " 0.49)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2k = mcmc(P=P,priori='donald',N=200000,status=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(x_model, t_model, val_x, val_t):\n",
    "    fig, axis = plt.subplots(2, 2, figsize=[6, 6])\n",
    "    labels = ['POH-PGME','Amoxicillin','6-APA','POHPG']\n",
    "    mlabels = ['POH-PGME model','Amoxicillin model','6-APA model','POHPG model']\n",
    "    style = ['.r','.g','.b','.k']\n",
    "    mstyle = ['-k','-k','-k','-k']    \n",
    "    for idx,ax in enumerate(axis.flatten()):\n",
    "        ax.plot(val_t, val_x[:, idx], style[idx], label=labels[idx],linewidth=0.5,markersize=5)\n",
    "        ax.plot(t_model, x_model[:, idx], mstyle[idx], label=mlabels[idx],linewidth=0.9,markersize=3)\n",
    "        ax.set_title(f'{labels[idx]}')\n",
    "        ax.set_ylim([val_x[:, idx].min()-5, val_x[:, idx].max()+5])\n",
    "        ax.set_xlim([0, val_t[-1]+5])\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_deviation(model_output, experimental_data):\n",
    "    \n",
    "    exp_mass = np.sum(model_output, axis=1)    \n",
    "    model_mass = np.sum(experimental_data, axis=1)\n",
    "\n",
    "    mass_deviation = np.sum(np.abs(exp_mass - model_mass))\n",
    "    return mass_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all(P_new,less_bad=False):\n",
    "    x_names = ['ester_mm', 'amox_mm', 'apa_mm', 'aoh_mm']\n",
    "\n",
    "    total_error = 0\n",
    "    if less_bad:\n",
    "        surface_error = np.zeros((len(data_frames),3)) # columns = mse error, ester init, apa init \n",
    "    else:\n",
    "        surface_error = np.zeros((len(data_frames),3)) # columns = mse error, ester init, apa init \n",
    "    \n",
    "    total_mass_error = 0\n",
    "    for idx,df in enumerate(data_frames):\n",
    "        x_target = df.loc[:,x_names].to_numpy()\n",
    "        t_target = df['apa_t'].to_numpy()\n",
    "    \n",
    "        ic = x_target[0]\n",
    "        \n",
    "\n",
    "        surface_error[idx,1] = ic[0] # ester\n",
    "        surface_error[idx,2] = ic[2] # apa\n",
    "        \n",
    "\n",
    "        if ((ic[0] == 20 and ic[2] == 60) or (ic[0] == 80 and ic[2] == 60)) and (less_bad):\n",
    "            surface_error[idx,0] = 0\n",
    "            continue\n",
    "\n",
    "        t_model = np.linspace(t_target[0],t_target[-1],40)\n",
    "        \n",
    "        sol = ode15s_amox(P_new,ic,t_model)\n",
    "        sol_val = ode15s_amox(P_new,ic,t_target).T\n",
    "\n",
    "        error = root_mean_squared_error(x_target.T, sol_val)\n",
    "        mass_error = mass_deviation(sol_val,x_target.T)\n",
    "        r2 = r2_score(x_target.T,sol_val)\n",
    "\n",
    "        surface_error[idx,0] = error\n",
    "\n",
    "        total_error += error\n",
    "        total_mass_error += mass_error\n",
    "        \n",
    "        print(f'Error {ic}: {error}\\tmass: {mass_error}\\tr2: {r2}')\n",
    "\n",
    "        x_model = sol.T\n",
    "        model_eval(x_model.T,t_model,x_target,t_target)\n",
    "    surfacedf = pd.DataFrame(surface_error,columns=['RMSE','Ester','APA'])\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    sns.scatterplot(data=surfacedf, x='Ester', y='APA', size='RMSE', hue='RMSE', sizes=(20, 200),legend='full')\n",
    "    plt.legend(title='Error Value', loc='upper right', bbox_to_anchor=(-0.15, 1))\n",
    "    #sns.heatmap(surfacedf,annot=True,fmt=\".3f\")\n",
    "    print(f'Total error: {total_error/len(data_frames)}\\tmass error:{total_mass_error/len(data_frames)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['k2',\n",
    "'k3',\n",
    "'k4',\n",
    "'k5',\n",
    "'KS',\n",
    "'KP',\n",
    "'KN',\n",
    "'kmenos4']\n",
    "\n",
    "labels_df = ['k2',\n",
    "'k3',\n",
    "'k4',\n",
    "'k5',\n",
    "'KS',\n",
    "'KP',\n",
    "'KN',\n",
    "'kmenos4','aceitacao']\n",
    "\n",
    "\n",
    "# all_P = [luci_P,lucas_P,process_P,optimized_P]\n",
    "#names = ['multi_luci','multi_lucas','multi_process','multi_bestnm']\n",
    "Ns = [100000,200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../dados\\\\25.46nh30ab30.csv', '../dados\\\\25.47nh5ab80.csv', '../dados\\\\5.100nh40ab80.csv', '../dados\\\\5.102nh20ab40.csv', '../dados\\\\5.103nh40ab30.csv', '../dados\\\\5.106nh100ab40.csv', '../dados\\\\5.107nh55ab55.csv', '../dados\\\\5.109nh5ab55.csv', '../dados\\\\5.110nh10ab55.csv', '../dados\\\\5.112nh78ab35.csv', '../dados\\\\5.48nh20ab80.csv', '../dados\\\\5.80nh12ab40.csv', '../dados\\\\5.81nh5ab30.csv']\n",
      "Index(['ester_mm', 'amox_mm', 'apa_mm', 'aoh_mm', 'apa_t'], dtype='object')\n",
      "['25.46nh30ab30', '25.47nh5ab80', '5.100nh40ab80', '5.102nh20ab40', '5.103nh40ab30', '5.106nh100ab40', '5.107nh55ab55', '5.109nh5ab55', '5.110nh10ab55', '5.112nh78ab35', '5.48nh20ab80', '5.80nh12ab40', '5.81nh5ab30']\n",
      "[array([30.,  0., 30.,  0.]), array([80.,  0.,  5.,  0.]), array([80.,  0., 40.,  0.]), array([40.5       ,  0.        , 21.75      ,  3.37262013]), array([30.4 ,  0.  , 43.  ,  2.55]), array([4.00389864e+01, 6.40149834e-02, 1.00045181e+02, 1.42108547e+00]), array([55.      ,  0.      , 55.      ,  0.623377]), array([55.,  0.,  5.,  0.]), array([55.,  0., 10.,  0.]), array([32.5,  0. , 78. ,  2.5]), array([80.,  0., 20.,  0.]), array([38.75,  0.  , 12.  ,  1.4 ]), array([30.,  0.,  5.,  0.])]\n"
     ]
    }
   ],
   "source": [
    "CIs = []\n",
    "\n",
    "def import_dfs_less_bad():\n",
    "    # Path to the folder containing CSV files\n",
    "    folder_path = '../dados/'\n",
    "\n",
    "    # Get a list of all CSV files in the folder\n",
    "    csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "    # Initialize an empty list to hold dataframes\n",
    "    data_frames = []\n",
    "\n",
    "    # Read the first CSV file to establish the schema\n",
    "    schema = ['ester_mm', 'amox_mm', 'apa_mm', 'aoh_mm','apa_t']\n",
    "\n",
    "    csv_files.remove(\"../dados\\\\25.45nh60ab20.csv\")\n",
    "    csv_files.remove(\"../dados\\\\nh60ab80.csv\")\n",
    "    print(csv_files)\n",
    "    # Load each remaining CSV file, reorder columns, and append to the list\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)  \n",
    "\n",
    "        df = df[schema]  # Reorder columns to match the schema\n",
    "        data_frames.append(df)\n",
    "        CIs.append(df.iloc[0,:4].to_numpy())\n",
    "    csv_files = [name.split('\\\\')[-1].rstrip('.csv') for name in csv_files]\n",
    "\n",
    "\n",
    "    return data_frames,csv_files \n",
    "data_frames,file_list = import_dfs_less_bad()\n",
    "print(data_frames[0].columns)\n",
    "print(file_list)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.48330172706005"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_performance(P,plot=False,less_bad=False):\n",
    "    total_error = 0\n",
    "    x_names = ['ester_mm', 'amox_mm', 'apa_mm', 'aoh_mm']\n",
    "    for exp_name,df_exp in zip(file_list,data_frames):\n",
    "        if (exp_name == '25.45nh60ab20' or exp_name == 'nh60ab80') and less_bad:\n",
    "            continue\n",
    "        x_target = df_exp.loc[:,x_names].to_numpy()\n",
    "        t_target = df_exp['apa_t'].to_numpy()\n",
    "        \n",
    "        ic = x_target[0]\n",
    "        t_model = np.linspace(t_target[0],t_target[-1],len(t_target))\n",
    "        \n",
    "        sol_val = ode15s_amox(P,ic,t_target).T\n",
    "        x_model = sol_val\n",
    "        error = root_mean_squared_error(x_target.T, sol_val)\n",
    "\n",
    "        total_error += error\n",
    "        if plot:\n",
    "            print(f'Error {exp_name}: {error}')\n",
    "        \n",
    "            model_eval(x_model,t_target,x_target,t_target)\n",
    "    if plot:\n",
    "        print('total error: ',total_error)\n",
    "    return total_error\n",
    "all_par_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
